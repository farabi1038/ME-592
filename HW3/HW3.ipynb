{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f116426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n",
      "name of image :1006 (3).jpg prediction: 1\n",
      "name of image :1007 (2).jpg prediction: 1\n",
      "name of image :1006 (2).jpg prediction: 1\n",
      "name of image :1004 (2).jpg prediction: 4\n",
      "name of image :1001_C (2).jpg prediction: 1\n",
      "name of image :1005 (2).jpg prediction: 4\n",
      "name of image :1009 (2).jpg prediction: 4\n",
      "name of image :1001 (3).jpg prediction: 6\n",
      "name of image :1001 (2).jpg prediction: 4\n",
      "name of image :1008 (2).jpg prediction: 1\n",
      "name of image :1003 (2).jpg prediction: 4\n",
      "name of image :1002 (2).jpg prediction: 4\n",
      "name of image :1005_C (2).jpg prediction: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using:', device)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            #2,3,300,300\n",
    "            nn.Conv2d(3, 16, kernel_size=3), nn.ReLU(),\n",
    "            #\n",
    "            nn.Conv2d(16, 16, kernel_size=3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "        ).to(device)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('enter',x.shape)\n",
    "        x = self.model(x)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "model = torch.load('/Users/ibnefarabishihab/Desktop/Course Materials/ME 592/task2_50.pth',map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256,256)),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "path='/Users/ibnefarabishihab/Desktop/Course Materials/ME 592/hw3/cropped/'\n",
    "for i in os.listdir(path):\n",
    "    img = Image.open(path+str(i))\n",
    "    img_tensor = transforms(img)\n",
    "    img_tensor.unsqueeze_(0)\n",
    "    output = model(img_tensor)\n",
    "    argmax = output.argmax(\n",
    "                dim=1)\n",
    "    print('name of image :'+str(i),'prediction: '+str(int(argmax)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec426c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7519e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c72868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37535b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "if checkpoint_dir:\n",
    "    model_state, optimizer_state = torch.load(\n",
    "        os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "    net.load_state_dict(model_state)\n",
    "    optimizer.load_state_dict(optimizer_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
