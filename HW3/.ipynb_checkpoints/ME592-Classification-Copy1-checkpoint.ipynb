{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51f97e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "import os \n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d9ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_zip_file = '/Users/ibnefarabishihab/Desktop/Course Materials/ME 592/hw3/Leaf_Images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0895d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_names = []\n",
    "for i in os.listdir(path_to_zip_file):\n",
    "    dir_names.append(i)\n",
    "dir_names.remove('.DS_Store')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2495c67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7', '6', '1', '8', '4', '3', '5']\n"
     ]
    }
   ],
   "source": [
    "print(dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6883c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14725\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((300,400)),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def batch(train_data,BS):\n",
    "    \n",
    "    num_batches = len(train_data) // BS\n",
    "    print(\"Num batches is {0}\".format(num_batches))\n",
    "    sequence = list(range(len(train_data)))\n",
    "    np.random.shuffle(sequence)  # To shuffle the training data\n",
    "    subsets = [Subset(train_data, sequence[i * BS: (i + 1) * BS]) for i in range(num_batches)]\n",
    "    train_loader = [DataLoader(sub, batch_size=BS) for sub in subsets]  # Create multiple batches, each with BS numberof samples\n",
    "    return train_loader\n",
    "\n",
    "# root_folder is the string containing address of the root image data directory \n",
    "dataset = torchvision.datasets.ImageFolder(root = path_to_zip_file, transform=transforms)\n",
    "#print(dataset.class_to_idx)\n",
    "\n",
    "print(len(dataset))\n",
    "batch_size=32\n",
    "num_workers=2\n",
    "train,test = torch.utils.data.random_split(dataset, [11781, 2944])\n",
    "trainLoader = torch.utils.data.DataLoader(train, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, drop_last=True, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(test, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, drop_last=True)\n",
    "\n",
    "\n",
    "#n = len(dataset)  # total number of examples\n",
    "#print(n)\n",
    "#n_test = int(0.1 * n)  # take ~10% for test\n",
    "#test_set = torch.utils.data.Subset(dataset, range(n_test))  # take first 10%\n",
    "#train_set = torch.utils.data.Subset(dataset, range(n_test, n))  # take the rest \n",
    "#for i in range(n_test):\n",
    "#    print(test_set[1][1])\n",
    "#train_set=[train_set[x] for x in range(20)]\n",
    "#test_set=[test_set[x] for x in range(5)]\n",
    "#print(train_set.class_to_idx)\n",
    "#trainLoader = torch.utils.data.DataLoader(train_set, batch_size=32)\n",
    "#testLoader = torch.utils.data.DataLoader(test_set, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dd0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_iter = iter(dataLoader)\n",
    "\n",
    "#images, labels = next(data_iter)\n",
    "#fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "#for ii in range(4):\n",
    "#    ax = axes[ii]\n",
    "#     helper.imshow(images[ii], ax=ax, normalize=False)\n",
    "    #plt.imshow(images[ii], ax=ax, normalize=False)\n",
    "    #plt.imshow(images[ii])\n",
    "#print(images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ec2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00430bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        #Input shape= (1,3,300,400)\n",
    "        \n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        #Shape= (1,12,300,400)\n",
    "        \n",
    "        \n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        #Shape= (1,12,300,400)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        #Shape= (1,12,300,400)\n",
    "        \n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        #Shape= (1,12,150,200)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        #Shape= (1,20,150,200)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        #Shape= (1,32,150,200)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=150 * 200 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        #print(\"input shape \",input.shape)\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        #print(\"relu1 shape \",output.shape)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "        #print(\"pool shape \",output.shape)    \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "        #print(\"conv2 shape \",output.shape)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        #print(\"conv3 shape \",output.shape)    \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "        #print(\"hi\",output.shape)    \n",
    "        output=output.view(-1,32*150*200)\n",
    "            \n",
    "        #print(\"before fc\",output.shape)     \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44722aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730943dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc83dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49600c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11781 1472\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "train_count = 11781\n",
    "test_count = 1472\n",
    "print(train_count,test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb31e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count=0\n",
    "#for i, (images,labels) in enumerate(train_set):\n",
    "#    print(labels)  \n",
    "#images=images.unsqueeze(0)\n",
    "#print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/4049fmhs0r922gn11fms0t7r0000gn/T/ipykernel_5107/1525283677.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels=torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(trainLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        print('len of data ',len(images))    \n",
    "        optimizer.zero_grad()\n",
    "        #images=images.unsqueeze(0)\n",
    "        labels=torch.tensor(labels)\n",
    "        #labels=labels.view (1)\n",
    "        #print('before putting into model',images.shape)\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(testLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        #images=images.unsqueeze(0)\n",
    "        labels=torch.tensor(labels)\n",
    "        #labels=labels.view (1)    \n",
    "        outputs=model(images)\n",
    "        \n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        print(\"predicted value\",prediction)\n",
    "        print(\"label\",labels.data)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9426962",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9023e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "  ''' function to show image '''\n",
    "  img = img / 2 + 0.5 # unnormalize\n",
    "  npimg = img.numpy() # convert to numpy objects\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()\n",
    "\n",
    "# get random training images with iter function\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# call function on our images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print the class of the image\n",
    "print(' '.join('%s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb239927",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = 2\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5acd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d2584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
