{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnf6541/ME592HW4_IMAGEANALYTICS1/blob/main/HW4_gwd_retinanet_pytorch_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl6AQyd9eFjE"
      },
      "source": [
        "# ME 592 - RetinaNet in PyTorch - Global Wheat Detection \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c0FdgbwZoBA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "VR_0onxdeFjo"
      },
      "outputs": [],
      "source": [
        "### Cloning Github Repository \n",
        "!git clone https://github.com/yhenon/pytorch-retinanet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "In4EC3bmeFjt"
      },
      "outputs": [],
      "source": [
        "### Copying RetinaNet Folder to root dir so we can import it easily\n",
        "!cp -r pytorch-retinanet/retinanet ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "g5ZajGF7eFjv"
      },
      "outputs": [],
      "source": [
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "agwV-2TCeFjw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import make_grid \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from retinanet import model\n",
        "from retinanet.dataloader import collater, Resizer, Augmenter, Normalizer, UnNormalizer\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "DIR = \"/content/drive/MyDrive/Colab Notebooks/data/\"\n",
        "DIR_TRAIN = DIR + \"train\"\n",
        "DIR_TEST = DIR + \"test\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "wEIcejfVPZm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvOoicILeFjy"
      },
      "source": [
        "# Exploring Dataset ðŸ“Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "RzmN8hCxeFjz"
      },
      "outputs": [],
      "source": [
        "### Loading Dataset\n",
        "df = pd.read_csv(DIR + \"train.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utf4MtG9eFj1"
      },
      "source": [
        "Converting bbox list from original df to some appropriate form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "BbQHI_nJeFj2"
      },
      "outputs": [],
      "source": [
        "### Converting bbox list in appropriate form\n",
        "\n",
        "df['x'] = -1\n",
        "df['y'] = -1\n",
        "df['w'] = -1\n",
        "df['h'] = -1\n",
        "\n",
        "def expand_bbox(x):\n",
        "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
        "    if len(r) == 0:\n",
        "        r = [-1, -1, -1, -1]\n",
        "    return r\n",
        "\n",
        "df[['x', 'y', 'w', 'h']] = np.stack(df['bbox'].apply(lambda x: expand_bbox(x)))\n",
        "df.drop(columns=['bbox'], inplace=True)\n",
        "df['x'] = df['x'].astype(np.float)\n",
        "df['y'] = df['y'].astype(np.float)\n",
        "df['w'] = df['w'].astype(np.float)\n",
        "df['h'] = df['h'].astype(np.float)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEPzVRZoeFj5"
      },
      "source": [
        "Null Values, Unique Images, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "8M0XRV6geFj6"
      },
      "outputs": [],
      "source": [
        "### Null Values, Unique Images, etc.\n",
        "\n",
        "unq_values = df[\"image_id\"].unique()\n",
        "print(\"Total Records: \", len(df))\n",
        "print(\"Unique Images: \",len(unq_values))\n",
        "\n",
        "null_values = df.isnull().sum(axis = 0)\n",
        "print(\"\\n> Null Values in each column <\")\n",
        "print(null_values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": false,
        "trusted": true,
        "id": "R3fRs566eFj9"
      },
      "outputs": [],
      "source": [
        "### Data Sources\n",
        "\n",
        "sources = df[\"source\"].unique()\n",
        "print(\"Total Sources: \",len(sources))\n",
        "print(\"\\n> Sources <\\n\",sources)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "BalFCYnseFj-"
      },
      "outputs": [],
      "source": [
        "### Visualizing Source Distribution\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.title('Source Distribution', fontsize= 20)\n",
        "sns.countplot(x = \"source\", data = df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "xlAOOj0-eFj_"
      },
      "outputs": [],
      "source": [
        "### Splitting Train Dataset into train - val (80:20)\n",
        "\n",
        "images = df['image_id'].unique()\n",
        "valid_imgs = images[-674:]\n",
        "train_imgs = images[:-674]\n",
        "\n",
        "valid_df = df[df['image_id'].isin(valid_imgs)]\n",
        "train_df = df[df['image_id'].isin(train_imgs)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yisuR6deFkB"
      },
      "source": [
        "# Visualize Random Images with BBox ðŸ•µï¸â€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Yc5un5gVeFkB"
      },
      "outputs": [],
      "source": [
        "### Function to plot image\n",
        "\n",
        "def plot_img(image_name):\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 2, figsize = (10, 10))\n",
        "    ax = ax.flatten()\n",
        "    \n",
        "    records = df[df['image_id'] == image_name]\n",
        "    img_path = os.path.join(DIR_TRAIN, image_name + \".jpg\")\n",
        "    \n",
        "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "    image /= 255.0\n",
        "    image2 = image\n",
        "    \n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[0].imshow(image)\n",
        "    \n",
        "    for idx, row in records.iterrows():\n",
        "        box = row[['x', 'y', 'w', 'h']].values\n",
        "        xmin = box[0]\n",
        "        ymin = box[1]\n",
        "        width = box[2]\n",
        "        height = box[3]\n",
        "        \n",
        "        cv2.rectangle(image2, (int(xmin),int(ymin)), (int(xmin + width),int(ymin + height)), (255,0,0), 3)\n",
        "    \n",
        "    ax[1].set_title('Image with Bondary Box')\n",
        "    ax[1].imshow(image2)\n",
        "\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "v0vEHZfmeFkD"
      },
      "outputs": [],
      "source": [
        "### Pass any image id as parameter\n",
        "\n",
        "plot_img(\"0126b7d11\")\n",
        "plot_img(\"00333207f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "qHWOpdp_eFkE"
      },
      "source": [
        "# Preparing Dataset for Training ðŸ“‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "89Dgw_ANeFkF"
      },
      "outputs": [],
      "source": [
        "### Creating targets for model using Dataset Class\n",
        "\n",
        "class GWD(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, image_dir, mode = \"train\", transforms = None):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.image_ids = dataframe['image_id'].unique()\n",
        "        self.df = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "\n",
        "        # Retriving image id and records from df\n",
        "        image_id = self.image_ids[index]\n",
        "        records = self.df[self.df['image_id'] == image_id]\n",
        "\n",
        "        # Loading Image\n",
        "        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0\n",
        "\n",
        "        # If mode is set to train, then only we create targets\n",
        "        if self.mode == \"train\" or self.mode == \"valid\":\n",
        "\n",
        "            # Converting xmin, ymin, w, h to x1, y1, x2, y2\n",
        "            boxes = np.zeros((records.shape[0], 5))\n",
        "            boxes[:, 0:4] = records[['x', 'y', 'w', 'h']].values\n",
        "            boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
        "            boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
        "            boxes[:, 4] = 1 # This is for label, as we have only 1 class, it is always 1\n",
        "            \n",
        "            # Applying Transforms\n",
        "            sample = {'img': image, 'annot': boxes}\n",
        "                \n",
        "            if self.transforms:\n",
        "                sample = self.transforms(sample)\n",
        "\n",
        "            return sample\n",
        "        \n",
        "        elif self.mode == \"test\":\n",
        "            \n",
        "            # We just need to apply transoforms and return image\n",
        "            if self.transforms:\n",
        "                \n",
        "                sample = {'img' : image}\n",
        "                sample = self.transforms(sample)\n",
        "                \n",
        "            return sample\n",
        "        \n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.image_ids.shape[0]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "GXZsrOjZeFkI"
      },
      "outputs": [],
      "source": [
        "### Preparing Datasets and Dataloaders for Training \n",
        "\n",
        "# Dataset Object\n",
        "train_dataset = GWD(train_df, DIR_TRAIN, mode = \"train\", transforms = T.Compose([Augmenter(), Normalizer(), Resizer()]))\n",
        "valid_dataset = GWD(valid_df, DIR_TRAIN, mode = \"valid\", transforms = T.Compose([Normalizer(), Resizer()]))\n",
        "\n",
        "# DataLoaders\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 8,\n",
        "    shuffle = True,\n",
        "    num_workers = 4,\n",
        "    collate_fn = collater\n",
        ")\n",
        "\n",
        "valid_data_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = 8,\n",
        "    shuffle = True,\n",
        "    num_workers = 4,\n",
        "    collate_fn = collater\n",
        ")\n",
        "\n",
        "\n",
        "test_data_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle = True,\n",
        "    num_workers = 4,\n",
        "    collate_fn = collater\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjd63CX6eFkK"
      },
      "source": [
        "# Create Model - RetinaNet "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "jjB3sv_aeFkK"
      },
      "outputs": [],
      "source": [
        "### Utilize GPU if available\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "-NXF1OTpeFkL"
      },
      "outputs": [],
      "source": [
        "### We used Pre-trained Resnet34 as backbone because it showed the highest accuracy\n",
        "\n",
        "retinanet = model.resnet34(num_classes = 2, pretrained = True)\n",
        "\n",
        "# Loading Pre-trained model - if you load pre-trained model, comment above line.\n",
        "#retinanet = torch.load(\"path_to_.pt_file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "evDpX110eFkM"
      },
      "outputs": [],
      "source": [
        "### Preparing model for training\n",
        "\n",
        "# Defininig Optimizer\n",
        "optimizer = torch.optim.Adam(retinanet.parameters(), lr = 0.0001)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.5)\n",
        "\n",
        "retinanet.to(device)\n",
        "\n",
        "#No of epochs\n",
        "epochs = 15\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B02o7rxheFkN"
      },
      "source": [
        "# Now comes everbody's favorite part ðŸ˜‹, let's train it!\n",
        "I have defined functions to just improve the readability of the code, model and other parameters are defined outside."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "z18pUcpOeFkO"
      },
      "outputs": [],
      "source": [
        "### One Epoch - Train\n",
        "\n",
        "def train_one_epoch(epoch_num, train_data_loader):\n",
        "    \n",
        "    print(\"Epoch - {} Started\".format(epoch_num))\n",
        "    st = time.time()\n",
        "    retinanet.train()\n",
        "    \n",
        "    \n",
        "    epoch_loss = []\n",
        "\n",
        "    for iter_num, data in enumerate(train_data_loader):\n",
        "                \n",
        "        # Reseting gradients after each iter\n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        # Forward\n",
        "        classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot'].cuda().float()])\n",
        "                \n",
        "        # Calculating Loss\n",
        "        classification_loss = classification_loss.mean()\n",
        "        regression_loss = regression_loss.mean()\n",
        "\n",
        "        loss = classification_loss + regression_loss\n",
        "\n",
        "        if bool(loss == 0):\n",
        "            continue\n",
        "                \n",
        "        # Calculating Gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping\n",
        "        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
        "                \n",
        "        # Updating Weights\n",
        "        optimizer.step()\n",
        "\n",
        "        #Epoch Loss\n",
        "        epoch_loss.append(float(loss))\n",
        "\n",
        "            \n",
        "        print(\n",
        "            'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
        "                epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n",
        "\n",
        "        del classification_loss\n",
        "        del regression_loss\n",
        "        \n",
        "    # Update the learning rate\n",
        "    #if lr_scheduler is not None:\n",
        "        #lr_scheduler.step()\n",
        "        \n",
        "    et = time.time()\n",
        "    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n",
        "    \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "OmBapYs5eFkP"
      },
      "outputs": [],
      "source": [
        "### One Epoch - Valid\n",
        "\n",
        "def valid_one_epoch(epoch_num, valid_data_loader):\n",
        "    \n",
        "    print(\"Epoch - {} Started\".format(epoch_num))\n",
        "    st = time.time()\n",
        "    \n",
        "    epoch_loss = []\n",
        "\n",
        "    for iter_num, data in enumerate(valid_data_loader):\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # Forward\n",
        "            classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot'].cuda().float()])\n",
        "\n",
        "            # Calculating Loss\n",
        "            classification_loss = classification_loss.mean()\n",
        "            regression_loss = regression_loss.mean()\n",
        "            loss = classification_loss + regression_loss\n",
        "\n",
        "            #Epoch Loss\n",
        "            epoch_loss.append(float(loss))\n",
        "\n",
        "            print(\n",
        "                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
        "                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n",
        "\n",
        "            del classification_loss\n",
        "            del regression_loss\n",
        "        \n",
        "    et = time.time()\n",
        "    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n",
        "    \n",
        "    # Save Model after each epoch\n",
        "    torch.save(retinanet, \"/content/drive/MyDrive/Homework4/Homework4/retinanet_gwd_18_1.pt\")\n",
        "    \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "collapsed": true,
        "trusted": true,
        "id": "NFtnGZkfeFkT"
      },
      "outputs": [],
      "source": [
        "### Training Loop\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    # Call train function\n",
        "    train_one_epoch(epoch, train_data_loader)\n",
        "    \n",
        "    # Call valid function\n",
        "    valid_one_epoch(epoch, valid_data_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "FJfOF_YaeFkU"
      },
      "outputs": [],
      "source": [
        "### Sample Results\n",
        "retinanet.eval()\n",
        "unnormalize = UnNormalizer()\n",
        "\n",
        "for iter_num, data in enumerate(test_data_loader):\n",
        "    \n",
        "    # Getting Predictions\n",
        "    scores, classification, transformed_anchors = retinanet(data['img'].cuda().float())\n",
        "    \n",
        "    idxs = np.where(scores.cpu()>0.5)\n",
        "    img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n",
        "    \n",
        "    img[img<0] = 0\n",
        "    img[img>255] = 255\n",
        "\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "    img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "    \n",
        "    for j in range(idxs[0].shape[0]):\n",
        "        bbox = transformed_anchors[idxs[0][j], :]\n",
        "        x1 = int(bbox[0])\n",
        "        y1 = int(bbox[1])\n",
        "        x2 = int(bbox[2])\n",
        "        y2 = int(bbox[3])\n",
        "\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color = (0, 0, 255), thickness = 2)\n",
        "        \n",
        "    ax.imshow(img)\n",
        "    \n",
        "    break\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the model can draw appropriate bounding boxes and detect each wheat very well as you are able to see above an image."
      ],
      "metadata": {
        "id": "dbDnr8aIbuax"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "HW4_gwd_retinanet_pytorch_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}